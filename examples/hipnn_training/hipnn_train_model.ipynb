{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "666d2805-04c7-4bb6-aeda-021a85b08195",
   "metadata": {},
   "source": [
    "# Example of training the model using the data set from this paper https://doi.org/10.1073/pnas.2120333119."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea410b7-5530-4ec1-987c-71e630442f83",
   "metadata": {},
   "source": [
    "## Training to Energies (eV) and gradients (eV/A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d69fce-1d14-4b0c-9182-123960721bd5",
   "metadata": {},
   "source": [
    "## Here, energies are E_total - E_isolated_atoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0be74f84-f719-43aa-b265-f09ee8050eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(20000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 20 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maxim/anaconda3/envs/hipnn_1/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nit is fine to see the following message below:\\n\\nJavascript Error: IPython is not defined\\n\\nAutosaving every 20 seconds\\n\\n.../lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\\n  from .autonotebook import tqdm as notebook_tqdm\\n\\nDecorating your function! <function KSA_XL_BOMD.one_step at 0x7fb9febfbe50>\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------------------------- #\n",
    "# to save output in log file #\n",
    "# ---------------------------- #\n",
    "##############################################\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "nblog = open(\"train1.log\", \"w+\")\n",
    "sys.stdout.echo = nblog\n",
    "sys.stderr.echo = nblog\n",
    "\n",
    "get_ipython().log.handlers[0].stream = nblog\n",
    "get_ipython().log.setLevel(logging.INFO)\n",
    "\n",
    "%autosave 20\n",
    "##############################################\n",
    "\n",
    "\n",
    "# ---------------- #\n",
    "# Imported Modules #\n",
    "# ---------------- #\n",
    "import os\n",
    "import sys\n",
    "### path to PYSEQM ###\n",
    "sys.path.insert(1, \"/home/maxim/Projects/git2/PYSEQM_dev/\")\n",
    "#sys.path.insert(1, '/home/maxim/Projects/pyseqm_d/My_d_combined/PYSEQM_dev/')\n",
    "\n",
    "### path to HIPNN ###\n",
    "sys.path.append('/home/maxim/Projects/hipnn/hippynn')\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from hippynn.interfaces.pyseqm_interface.seqm_nodes import *\n",
    "from hippynn.interfaces.pyseqm_interface.callback import update_scf_eps, save_and_stop_after\n",
    "import hippynn.interfaces.pyseqm_interface\n",
    "import hippynn\n",
    "from hippynn.graphs import inputs, networks, targets, physics\n",
    "from hippynn.graphs import loss\n",
    "from hippynn import plotting\n",
    "from hippynn.databases import DirectoryDatabase\n",
    "from hippynn.experiment.assembly import assemble_for_training\n",
    "from hippynn.experiment.controllers import RaiseBatchSizeOnPlateau,PatienceController\n",
    "from hippynn.experiment import setup_training\n",
    "from hippynn.experiment import train_model\n",
    "import seqm\n",
    "from seqm.basics import parameterlist\n",
    "\n",
    "from hippynn.graphs.nodes.base.algebra import ValueNode\n",
    "\n",
    "### keeps SCF loops silent ###\n",
    "seqm.seqm_functions.scf_loop.debug = False\n",
    "\n",
    "hippynn.interfaces.pyseqm_interface.check.debug = True\n",
    "\n",
    "### maximum allowed SCF iterations ###\n",
    "seqm.seqm_functions.scf_loop.MAX_ITER = 100\n",
    "\n",
    "# torch.cuda.set_device(0) # Don't try this if you want CPU training!\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use(\"agg\")\n",
    "\n",
    "'''\n",
    "it is fine to see the following message below:\n",
    "\n",
    "Javascript Error: IPython is not defined\n",
    "\n",
    "Autosaving every 20 seconds\n",
    "\n",
    ".../lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
    "  from .autonotebook import tqdm as notebook_tqdm\n",
    "\n",
    "Decorating your function! <function KSA_XL_BOMD.one_step at 0x7fb9febfbe50>\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41d443d0-38f7-4938-80c8-aea14d6eee38",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PULL DATA SET. Don't run this cell if the data is already downloaded ###\n",
    "\n",
    "from urllib.request import urlretrieve\n",
    "url = 'https://figshare.com/ndownloader/articles/19640052/versions/1'\n",
    "dst = 'training_set/data.zip'\n",
    "urlretrieve(url, dst)\n",
    "\n",
    "dlDict = {\"training_set/EtEi.npy\":\"https://figshare.com/ndownloader/files/35845121\",\n",
    "          \"training_set/Gradient_ev.npy\":\"https://figshare.com/ndownloader/files/35845133\",\n",
    "          \"training_set/R.npy\":\"https://figshare.com/ndownloader/files/35845145\",\n",
    "          \"training_set/Z.npy\":\"https://figshare.com/ndownloader/files/35845163\"}\n",
    "for file in list(dlDict):\n",
    "    urlretrieve(dlDict[file],file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9ca5eb-6624-4df5-9841-b15ccd3261e3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "restarting <class 'hippynn.databases.ondisk.DirectoryDatabase'>\n",
      "Arrays found:  {'R': 'R.npy', 'Z': 'Z.npy', 'EtEi': 'EtEi.npy', 'Gradient_ev': 'Gradient_ev.npy'}\n",
      "Data types:\n",
      "{'R': dtype('float64'), 'Z': dtype('int64'), 'EtEi': dtype('float64'), 'Gradient_ev': dtype('float64')}\n",
      "All arrays:\n",
      "--------------------------------------------------------------------------------------\n",
      "| Name               | dtype              | shape                                    |\n",
      "--------------------------------------------------------------------------------------\n",
      "| R                  | dtype('float64')   | (618409, 18, 3)                          |\n",
      "| Z                  | dtype('int64')     | (618409, 18)                             |\n",
      "| EtEi               | dtype('float64')   | (618409,)                                |\n",
      "| Gradient_ev        | dtype('float64')   | (618409, 18, 3)                          |\n",
      "--------------------------------------------------------------------------------------\n",
      "Database: Using auto-generated data indices\n",
      "Arrays for split: ignore\n",
      "--------------------------------------------------------------------------------------\n",
      "| Name               | dtype              | shape                                    |\n",
      "--------------------------------------------------------------------------------------\n",
      "| R                  | torch.float64      | torch.Size([556568, 18, 3])              |\n",
      "| Z                  | torch.int64        | torch.Size([556568, 18])                 |\n",
      "| EtEi               | torch.float64      | torch.Size([556568])                     |\n",
      "| Gradient_ev        | torch.float64      | torch.Size([556568, 18, 3])              |\n",
      "| indices            | torch.int64        | torch.Size([556568])                     |\n",
      "| split_indices      | torch.int64        | torch.Size([556568])                     |\n",
      "--------------------------------------------------------------------------------------\n",
      "Arrays for split: test\n",
      "--------------------------------------------------------------------------------------\n",
      "| Name               | dtype              | shape                                    |\n",
      "--------------------------------------------------------------------------------------\n",
      "| R                  | torch.float64      | torch.Size([6184, 18, 3])                |\n",
      "| Z                  | torch.int64        | torch.Size([6184, 18])                   |\n",
      "| EtEi               | torch.float64      | torch.Size([6184])                       |\n",
      "| Gradient_ev        | torch.float64      | torch.Size([6184, 18, 3])                |\n",
      "| indices            | torch.int64        | torch.Size([6184])                       |\n",
      "| split_indices      | torch.int64        | torch.Size([6184])                       |\n",
      "--------------------------------------------------------------------------------------\n",
      "Arrays for split: valid\n",
      "--------------------------------------------------------------------------------------\n",
      "| Name               | dtype              | shape                                    |\n",
      "--------------------------------------------------------------------------------------\n",
      "| R                  | torch.float64      | torch.Size([6184, 18, 3])                |\n",
      "| Z                  | torch.int64        | torch.Size([6184, 18])                   |\n",
      "| EtEi               | torch.float64      | torch.Size([6184])                       |\n",
      "| Gradient_ev        | torch.float64      | torch.Size([6184, 18, 3])                |\n",
      "| indices            | torch.int64        | torch.Size([6184])                       |\n",
      "| split_indices      | torch.int64        | torch.Size([6184])                       |\n",
      "--------------------------------------------------------------------------------------\n",
      "Arrays for split: train\n",
      "--------------------------------------------------------------------------------------\n",
      "| Name               | dtype              | shape                                    |\n",
      "--------------------------------------------------------------------------------------\n",
      "| R                  | torch.float64      | torch.Size([49473, 18, 3])               |\n",
      "| Z                  | torch.int64        | torch.Size([49473, 18])                  |\n",
      "| EtEi               | torch.float64      | torch.Size([49473])                      |\n",
      "| Gradient_ev        | torch.float64      | torch.Size([49473, 18, 3])               |\n",
      "| indices            | torch.int64        | torch.Size([49473])                      |\n",
      "| split_indices      | torch.int64        | torch.Size([49473])                      |\n",
      "--------------------------------------------------------------------------------------\n",
      "Beginning training.\n",
      "Model:\n",
      "Inputs:\n",
      "\t I0 : PositionsNode('Positions(db_name='R')')<0x7f66cc5a0730>\n",
      "\t I1 : SpeciesNode('Species(db_name='Z')')<0x7f66cc5a07f0>\n",
      "\t I2 : LossTrueNode('SEQM_Energy.Etot_m_Eiso-true')<0x7f66cc534820>\n",
      "\t I3 : LossTrueNode('Species(db_name='Z')-true')<0x7f66cc5a0820>\n",
      "Outputs:\n",
      "\t O0 : AtomMaskNode('Atom_Mask')<0x7f66cc534fa0>\n",
      "\t O1 : PerAtom('PeratomTrue')<0x7f66cc5a08e0>\n",
      "\t O2 : IndexNode('SEQM_Atom_Params.atom_charges')<0x7f66cc5a09a0>\n",
      "\t O3 : SEQM_MolMaskNode('SEQM_MolMask')<0x7f66cc5345e0>\n",
      "\t O4 : SEQM_MaskOnMolNode('SEQM_MaskMol_Pred')<0x7f66cc534790>\n",
      "\t O5 : SEQM_MaskOnMolNode('SEQM_PerAtom_Pred')<0x7f66cc534d00>\n",
      "\t O6 : ScaleNode('Scale')<0x7f66cc534670>\n",
      "\t O7 : SEQM_MaskOnMolAtomNode('SEQM_MaskMolAtom_Pred')<0x7f66cc534490>\n",
      "\t O8 : _LPReg('L^P_Reg(HIPNN_seqm,p=2)')<0x7f66cc534100>\n",
      "Order:\n",
      "I1-------------------> O0  : Atom_Mask\n",
      "I2-------------------> H1  : Atleast2D(LossTrueNode('SEQM_Energy.Etot_m_Eiso-true')<0x7f2c7cab2640>)\n",
      "I1-------------------> H2  : OneHot\n",
      "H2-------------------> H3  : OneHot.encoding\n",
      "H2-------------------> H4  : OneHot.nonblank\n",
      "H3,H4----------------> H5  : PaddingIndexer\n",
      "H5-------------------> H6  : PaddingIndexer.n_molecules\n",
      "H5-------------------> H7  : PaddingIndexer.indexed_features\n",
      "H5-------------------> H8  : PaddingIndexer.n_atoms_max\n",
      "H5-------------------> H9  : PaddingIndexer.inv_real_atoms\n",
      "H5-------------------> H10 : PaddingIndexer.real_atoms\n",
      "I0,H10,H4,H9---------> H11 : PairIndexer\n",
      "H11------------------> H12 : PairIndexer.pair_dist\n",
      "H11------------------> H13 : PairIndexer.pair_first\n",
      "H11------------------> H14 : PairIndexer.pair_second\n",
      "H14,H12,H7,H13-------> H15 : HIPNN_seqm\n",
      "H15------------------> H16 : SEQM_Atom_Params\n",
      "H15------------------> O8  : L^P_Reg(HIPNN_seqm,p=2)\n",
      "H16------------------> O2  : SEQM_Atom_Params.atom_charges\n",
      "H11------------------> H19 : PairIndexer.pair_coord\n",
      "H16------------------> H20 : SEQM_Atom_Params.partial_sums\n",
      "H16------------------> H21 : SEQM_Atom_Params.charge_hierarchality\n",
      "I0,I1,O2-------------> H22 : SEQM_Energy\n",
      "H22------------------> H23 : SEQM_Energy.atomic_charge\n",
      "H22------------------> H24 : SEQM_Energy.notconverged\n",
      "H24------------------> O3  : SEQM_MolMask\n",
      "H22------------------> H26 : SEQM_Energy.orbital_charges\n",
      "H22------------------> H27 : SEQM_Energy.isolated_atom_energy\n",
      "H22------------------> H28 : SEQM_Energy.nuclear_energy\n",
      "H22------------------> H29 : SEQM_Energy.electric_energy\n",
      "H22------------------> H30 : SEQM_Energy.single_particle_density_matrix\n",
      "H22------------------> H31 : SEQM_Energy.orbital_energies\n",
      "H22------------------> H32 : SEQM_Energy.Etot_m_Eiso\n",
      "H32,I1---------------> H33 : PeratomPredicted\n",
      "I0,H32---------------> H34 : gradients\n",
      "O0,H34,O3------------> O7  : SEQM_MaskMolAtom_Pred\n",
      "H32,O3---------------> O4  : SEQM_MaskMol_Pred\n",
      "O3,H33---------------> O5  : SEQM_PerAtom_Pred\n",
      "H24------------------> O6  : Scale\n",
      "H22------------------> H39 : SEQM_Energy.mol_energy\n",
      "H5-------------------> H40 : PaddingIndexer.mol_index\n",
      "I3,H1----------------> O1  : PeratomTrue\n",
      "H5-------------------> H42 : PaddingIndexer.atom_index\n",
      "Model Params:\n",
      "cuda:0 Fixed torch.int64 torch.Size([9]) moddict.node2.species_map\n",
      "cuda:0 Learned torch.float64 torch.Size([18, 50, 4]) moddict.node15.blocks.0.0.base_layer.int_weights\n",
      "cuda:0 Learned torch.float64 torch.Size([1, 18]) moddict.node15.blocks.0.0.base_layer.sensitivity.mu\n",
      "cuda:0 Learned torch.float64 torch.Size([1, 18]) moddict.node15.blocks.0.0.base_layer.sensitivity.sigma\n",
      "cuda:0 Learned torch.float64 torch.Size([50, 4]) moddict.node15.blocks.0.0.base_layer.selfint.weight\n",
      "cuda:0 Learned torch.float64 torch.Size([50]) moddict.node15.blocks.0.0.base_layer.selfint.bias\n",
      "cuda:0 Learned torch.float64 torch.Size([50, 50]) moddict.node15.blocks.0.0.res_layer.weight\n",
      "cuda:0 Learned torch.float64 torch.Size([50]) moddict.node15.blocks.0.0.res_layer.bias\n",
      "cuda:0 Learned torch.float64 torch.Size([50, 4]) moddict.node15.blocks.0.0.adjust_layer.weight\n",
      "cuda:0 Learned torch.float64 torch.Size([50, 50]) moddict.node15.blocks.0.1.base_layer.weight\n",
      "cuda:0 Learned torch.float64 torch.Size([50]) moddict.node15.blocks.0.1.base_layer.bias\n",
      "cuda:0 Learned torch.float64 torch.Size([50, 50]) moddict.node15.blocks.0.1.res_layer.weight\n",
      "cuda:0 Learned torch.float64 torch.Size([50]) moddict.node15.blocks.0.1.res_layer.bias\n",
      "cuda:0 Learned torch.float64 torch.Size([50, 50]) moddict.node15.blocks.0.2.base_layer.weight\n",
      "cuda:0 Learned torch.float64 torch.Size([50]) moddict.node15.blocks.0.2.base_layer.bias\n",
      "cuda:0 Learned torch.float64 torch.Size([50, 50]) moddict.node15.blocks.0.2.res_layer.weight\n",
      "cuda:0 Learned torch.float64 torch.Size([50]) moddict.node15.blocks.0.2.res_layer.bias\n",
      "cuda:0 Learned torch.float64 torch.Size([50, 50]) moddict.node15.blocks.0.3.base_layer.weight\n",
      "cuda:0 Learned torch.float64 torch.Size([50]) moddict.node15.blocks.0.3.base_layer.bias\n",
      "cuda:0 Learned torch.float64 torch.Size([50, 50]) moddict.node15.blocks.0.3.res_layer.weight\n",
      "cuda:0 Learned torch.float64 torch.Size([50]) moddict.node15.blocks.0.3.res_layer.bias\n",
      "cuda:0 Learned torch.float64 torch.Size([18, 50, 50]) moddict.node15.blocks.1.0.base_layer.int_weights\n",
      "cuda:0 Learned torch.float64 torch.Size([1, 18]) moddict.node15.blocks.1.0.base_layer.sensitivity.mu\n",
      "cuda:0 Learned torch.float64 torch.Size([1, 18]) moddict.node15.blocks.1.0.base_layer.sensitivity.sigma\n",
      "cuda:0 Learned torch.float64 torch.Size([50, 50]) moddict.node15.blocks.1.0.base_layer.selfint.weight\n",
      "cuda:0 Learned torch.float64 torch.Size([50]) moddict.node15.blocks.1.0.base_layer.selfint.bias\n",
      "cuda:0 Learned torch.float64 torch.Size([50, 50]) moddict.node15.blocks.1.0.res_layer.weight\n",
      "cuda:0 Learned torch.float64 torch.Size([50]) moddict.node15.blocks.1.0.res_layer.bias\n",
      "cuda:0 Learned torch.float64 torch.Size([50, 50]) moddict.node15.blocks.1.1.base_layer.weight\n",
      "cuda:0 Learned torch.float64 torch.Size([50]) moddict.node15.blocks.1.1.base_layer.bias\n",
      "cuda:0 Learned torch.float64 torch.Size([50, 50]) moddict.node15.blocks.1.1.res_layer.weight\n",
      "cuda:0 Learned torch.float64 torch.Size([50]) moddict.node15.blocks.1.1.res_layer.bias\n",
      "cuda:0 Learned torch.float64 torch.Size([50, 50]) moddict.node15.blocks.1.2.base_layer.weight\n",
      "cuda:0 Learned torch.float64 torch.Size([50]) moddict.node15.blocks.1.2.base_layer.bias\n",
      "cuda:0 Learned torch.float64 torch.Size([50, 50]) moddict.node15.blocks.1.2.res_layer.weight\n",
      "cuda:0 Learned torch.float64 torch.Size([50]) moddict.node15.blocks.1.2.res_layer.bias\n",
      "cuda:0 Learned torch.float64 torch.Size([50, 50]) moddict.node15.blocks.1.3.base_layer.weight\n",
      "cuda:0 Learned torch.float64 torch.Size([50]) moddict.node15.blocks.1.3.base_layer.bias\n",
      "cuda:0 Learned torch.float64 torch.Size([50, 50]) moddict.node15.blocks.1.3.res_layer.weight\n",
      "cuda:0 Learned torch.float64 torch.Size([50]) moddict.node15.blocks.1.3.res_layer.bias\n",
      "cuda:0 Learned torch.float64 torch.Size([9, 4]) moddict.node16.layers.0.weight\n",
      "cuda:0 Learned torch.float64 torch.Size([9]) moddict.node16.layers.0.bias\n",
      "cuda:0 Learned torch.float64 torch.Size([9, 50]) moddict.node16.layers.1.weight\n",
      "cuda:0 Learned torch.float64 torch.Size([9]) moddict.node16.layers.1.bias\n",
      "cuda:0 Learned torch.float64 torch.Size([9, 50]) moddict.node16.layers.2.weight\n",
      "cuda:0 Learned torch.float64 torch.Size([9]) moddict.node16.layers.2.bias\n",
      "cuda:0 Fixed torch.float64 torch.Size([9, 9]) moddict.node22.p\n",
      "cuda:0 Fixed torch.float64 torch.Size([9]) moddict.node22.weight\n",
      "cuda:0 Fixed torch.float64 torch.Size([9, 21]) moddict.node22.energy.packpar.p\n",
      "cuda:0 Fixed torch.float64 torch.Size([9, 9]) moddict.node22.energy.packpar.alpha\n",
      "cuda:0 Fixed torch.float64 torch.Size([9, 9]) moddict.node22.energy.packpar.chi\n",
      "cuda:0 Fixed torch.float64 torch.Size([]) moddict.node22.energy.hamiltonian.eps\n",
      "cuda:0 Fixed torch.float64 torch.Size([]) moddict.node22.energy.hamiltonian.scf_backward_eps\n",
      "cuda:0 Fixed torch.float64 torch.Size([73]) moddict.node22.const.atomic_num\n",
      "cuda:0 Fixed torch.float64 torch.Size([73]) moddict.node22.const.tore\n",
      "cuda:0 Fixed torch.float64 torch.Size([73]) moddict.node22.const.iso\n",
      "cuda:0 Fixed torch.float64 torch.Size([73]) moddict.node22.const.qn\n",
      "cuda:0 Fixed torch.int64 torch.Size([73]) moddict.node22.const.qn_int\n",
      "cuda:0 Fixed torch.int64 torch.Size([73]) moddict.node22.const.qnD_int\n",
      "cuda:0 Fixed torch.float64 torch.Size([73]) moddict.node22.const.ussc\n",
      "cuda:0 Fixed torch.float64 torch.Size([73]) moddict.node22.const.uppc\n",
      "cuda:0 Fixed torch.float64 torch.Size([73]) moddict.node22.const.gssc\n",
      "cuda:0 Fixed torch.float64 torch.Size([73]) moddict.node22.const.gspc\n",
      "cuda:0 Fixed torch.float64 torch.Size([73]) moddict.node22.const.hspc\n",
      "cuda:0 Fixed torch.float64 torch.Size([73]) moddict.node22.const.gp2c\n",
      "cuda:0 Fixed torch.float64 torch.Size([73]) moddict.node22.const.gppc\n",
      "cuda:0 Fixed torch.float64 torch.Size([73]) moddict.node22.const.eheat\n",
      "cuda:0 Fixed torch.float64 torch.Size([73]) moddict.node22.const.mass\n",
      "Total Count: 89882\n",
      "At least 20 epochs will be run\n",
      "__________________________________________________\n",
      "Epoch 21:\n",
      "Learning rate:    0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  21%|██        | 326/1547 [35:15<2:14:00,  6.59s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(30, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maxim/Projects/git2/PYSEQM_dev/seqm/seqm_functions/scf_loop.py:1579: UserWarning: SCF for 1/32 molecules doesn't converge after 100 iterations\n",
      "  warnings.warn(\"SCF for %d/%d molecules doesn't converge after %d iterations\" % (nnot, nmol, MAX_ITER))\n",
      "Training Batches:  30%|██▉       | 459/1547 [49:55<2:01:01,  6.67s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(25, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  68%|██████▊   | 1053/1547 [1:55:23<55:24,  6.73s/batch]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(26, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  73%|███████▎  | 1136/1547 [2:04:37<44:53,  6.55s/batch]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(23, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  83%|████████▎ | 1285/1547 [2:21:14<29:58,  6.86s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(11, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  84%|████████▍ | 1302/1547 [2:23:11<28:07,  6.89s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(23, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  93%|█████████▎| 1433/1547 [2:37:44<12:39,  6.66s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(11, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time:  10218.34 s\n",
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating train:  35%|███▍      | 27/78 [03:04<05:50,  6.87s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(63, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maxim/Projects/git2/PYSEQM_dev/seqm/seqm_functions/scf_loop.py:1579: UserWarning: SCF for 1/64 molecules doesn't converge after 100 iterations\n",
      "  warnings.warn(\"SCF for %d/%d molecules doesn't converge after %d iterations\" % (nnot, nmol, MAX_ITER))\n",
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making plots. Saved location: plots/epochs/epoch21/train\n",
      "Saving plot at plots/epochs/epoch21/train/EtEi.png\n",
      "Saving plot at plots/epochs/epoch21/train/grad.png\n",
      "Saving plot at plots/epochs/epoch21/train/PerAtomEn.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating valid:  88%|████████▊ | 85/97 [09:33<01:26,  7.18s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(44, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making plots. Saved location: plots/epochs/epoch21/valid\n",
      "Saving plot at plots/epochs/epoch21/valid/EtEi.png\n",
      "Saving plot at plots/epochs/epoch21/valid/grad.png\n",
      "Saving plot at plots/epochs/epoch21/valid/PerAtomEn.png\n",
      "                       train         valid\n",
      "------------------------------------------\n",
      "TperAtom MAE:    *  0.019708   *  0.019889\n",
      "Force-RMSE  :        0.33826        0.3314\n",
      "Force-MAE   :        0.22633       0.22474\n",
      "Force-RSQ   :        0.97175       0.97273\n",
      "MolEn-RMSE  :    *   0.31731   *   0.31175\n",
      "MolEn-MAE   :    *   0.24225   *   0.24138\n",
      "MolEn-RSQ   :        0.99943       0.99944\n",
      "L2Reg       :         684.29        684.29\n",
      "Loss-Err    :    *    1.0379   *    1.0244\n",
      "Loss-Reg    :     0.00068429    0.00068429\n",
      "Loss        :    *    1.0386   *    1.0251\n",
      "Best Loss-Err so far:   1.0244\n",
      "Epochs since last best: 0\n",
      "Current max epochs: 41\n",
      "Total epoch time:  11412.98 s\n",
      "from callback update_scf_eps\n",
      "SCF eps is updated:  3.893440000000001e-05 ==> 3.581964800000001e-05\n",
      "**** NEW BEST MODEL - Saving! ****\n",
      "__________________________________________________\n",
      "Epoch 22:\n",
      "Learning rate:    0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  17%|█▋        | 266/1547 [29:06<2:23:51,  6.74s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(2, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  40%|███▉      | 616/1547 [1:07:26<1:41:33,  6.54s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(17, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  43%|████▎     | 670/1547 [1:13:21<1:35:21,  6.52s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(6, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  51%|█████     | 783/1547 [1:25:51<1:23:25,  6.55s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(19, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  83%|████████▎ | 1283/1547 [2:21:05<28:47,  6.54s/batch]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(29, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  94%|█████████▍| 1453/1547 [2:39:52<10:16,  6.55s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(3, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time:  10209.09 s\n",
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making plots. Saved location: plots/epochs/epoch22/train\n",
      "Saving plot at plots/epochs/epoch22/train/EtEi.png\n",
      "Saving plot at plots/epochs/epoch22/train/grad.png\n",
      "Saving plot at plots/epochs/epoch22/train/PerAtomEn.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating valid:  88%|████████▊ | 85/97 [09:32<01:27,  7.26s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(44, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making plots. Saved location: plots/epochs/epoch22/valid\n",
      "Saving plot at plots/epochs/epoch22/valid/EtEi.png\n",
      "Saving plot at plots/epochs/epoch22/valid/grad.png\n",
      "Saving plot at plots/epochs/epoch22/valid/PerAtomEn.png\n",
      "                       train         valid\n",
      "------------------------------------------\n",
      "TperAtom MAE:       0.025294      0.025434\n",
      "Force-RMSE  :    *   0.31514   *   0.32029\n",
      "Force-MAE   :    *   0.21298   *   0.21163\n",
      "Force-RSQ   :        0.97489       0.97453\n",
      "MolEn-RMSE  :        0.39832       0.39087\n",
      "MolEn-MAE   :        0.30562       0.30206\n",
      "MolEn-RSQ   :        0.99905       0.99912\n",
      "L2Reg       :         697.53        697.53\n",
      "Loss-Err    :         1.1128        1.1078\n",
      "Loss-Reg    :     0.00069753    0.00069753\n",
      "Loss        :         1.1135        1.1085\n",
      "Best Loss-Err so far:   1.0244\n",
      "Epochs since last best: 1\n",
      "Current max epochs: 41\n",
      "Total epoch time:  11404.67 s\n",
      "__________________________________________________\n",
      "Epoch 23:\n",
      "Learning rate:    0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  11%|█▏        | 175/1547 [19:09<2:30:55,  6.60s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(27, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  18%|█▊        | 279/1547 [30:35<2:17:09,  6.49s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(1, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  44%|████▍     | 687/1547 [1:15:48<1:33:20,  6.51s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(4, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  51%|█████     | 790/1547 [1:27:15<1:21:36,  6.47s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(26, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  74%|███████▍  | 1148/1547 [2:06:33<43:42,  6.57s/batch] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(6, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  78%|███████▊  | 1210/1547 [2:13:20<36:00,  6.41s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(25, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time:  10207.65 s\n",
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating train:  69%|██████▉   | 54/78 [06:09<02:44,  6.84s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(23, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating train:  82%|████████▏ | 64/78 [07:18<01:35,  6.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(24, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making plots. Saved location: plots/epochs/epoch23/train\n",
      "Saving plot at plots/epochs/epoch23/train/EtEi.png\n",
      "Saving plot at plots/epochs/epoch23/train/grad.png\n",
      "Saving plot at plots/epochs/epoch23/train/PerAtomEn.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating valid:  88%|████████▊ | 85/97 [09:29<01:26,  7.24s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(44, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making plots. Saved location: plots/epochs/epoch23/valid\n",
      "Saving plot at plots/epochs/epoch23/valid/EtEi.png\n",
      "Saving plot at plots/epochs/epoch23/valid/grad.png\n",
      "Saving plot at plots/epochs/epoch23/valid/PerAtomEn.png\n",
      "                       train         valid\n",
      "------------------------------------------\n",
      "TperAtom MAE:    *  0.016104   *  0.016567\n",
      "Force-RMSE  :        0.31888   *   0.31085\n",
      "Force-MAE   :    *    0.2104   *   0.20852\n",
      "Force-RSQ   :        0.97512       0.97601\n",
      "MolEn-RMSE  :    *   0.25653   *   0.25414\n",
      "MolEn-MAE   :    *   0.19612   *    0.1985\n",
      "MolEn-RSQ   :        0.99962       0.99963\n",
      "L2Reg       :          711.7         711.7\n",
      "Loss-Err    :    *   0.91578   *   0.90595\n",
      "Loss-Reg    :      0.0007117     0.0007117\n",
      "Loss        :    *   0.91649   *   0.90667\n",
      "Best Loss-Err so far:  0.90595\n",
      "Patience for training restored.\n",
      "Epochs since last best: 0\n",
      "Current max epochs: 43\n",
      "Total epoch time:  11398.35 s\n",
      "from callback update_scf_eps\n",
      "SCF eps is updated:  3.581964800000001e-05 ==> 3.295407616000001e-05\n",
      "**** NEW BEST MODEL - Saving! ****\n",
      "__________________________________________________\n",
      "Epoch 24:\n",
      "Learning rate:    0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  14%|█▍        | 213/1547 [23:26<2:25:43,  6.55s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(15, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  37%|███▋      | 580/1547 [1:04:07<1:47:31,  6.67s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(9, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  39%|███▉      | 604/1547 [1:06:48<1:43:00,  6.55s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(1, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  42%|████▏     | 651/1547 [1:11:58<1:38:33,  6.60s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(9, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  43%|████▎     | 662/1547 [1:13:15<1:38:52,  6.70s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(9, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  45%|████▌     | 703/1547 [1:17:46<1:31:41,  6.52s/batch]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Training Batches:  45%|████▌     | 700/1547 [1:17:50<1:33:32,  6.63s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(20, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  54%|█████▍    | 833/1547 [1:32:39<1:19:18,  6.66s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(25, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  58%|█████▊    | 901/1547 [1:40:10<1:10:44,  6.57s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(1, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  83%|████████▎ | 1278/1547 [2:22:01<33:24,  7.45s/batch]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(19, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time:  10309.82 s\n",
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating train:  14%|█▍        | 11/78 [01:14<07:34,  6.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(49, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating train:  46%|████▌     | 36/78 [04:07<04:48,  6.86s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(51, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making plots. Saved location: plots/epochs/epoch25/train\n",
      "Saving plot at plots/epochs/epoch25/train/EtEi.png\n",
      "Saving plot at plots/epochs/epoch25/train/grad.png\n",
      "Saving plot at plots/epochs/epoch25/train/PerAtomEn.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating valid:  88%|████████▊ | 85/97 [09:33<01:27,  7.25s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(44, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making plots. Saved location: plots/epochs/epoch25/valid\n",
      "Saving plot at plots/epochs/epoch25/valid/EtEi.png\n",
      "Saving plot at plots/epochs/epoch25/valid/grad.png\n",
      "Saving plot at plots/epochs/epoch25/valid/PerAtomEn.png\n",
      "                       train         valid\n",
      "------------------------------------------\n",
      "TperAtom MAE:       0.051769      0.051872\n",
      "Force-RMSE  :        0.36352       0.36745\n",
      "Force-MAE   :        0.24791       0.24766\n",
      "Force-RSQ   :        0.96736       0.96648\n",
      "MolEn-RMSE  :        0.76599       0.77002\n",
      "MolEn-MAE   :        0.61619       0.61368\n",
      "MolEn-RSQ   :        0.99668       0.99659\n",
      "L2Reg       :         742.32        742.32\n",
      "Loss-Err    :         1.7426        1.7476\n",
      "Loss-Reg    :     0.00074232    0.00074232\n",
      "Loss        :         1.7434        1.7484\n",
      "Best Loss-Err so far:  0.90595\n",
      "Epochs since last best: 2\n",
      "Current max epochs: 43\n",
      "Total epoch time:  11504.77 s\n",
      "__________________________________________________\n",
      "Epoch 26:\n",
      "Learning rate:    0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:   3%|▎         | 45/1547 [04:56<2:44:26,  6.57s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(14, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  18%|█▊        | 276/1547 [30:42<2:19:08,  6.57s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(1, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  84%|████████▍ | 1303/1547 [2:24:21<26:44,  6.58s/batch]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(17, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  90%|████████▉ | 1386/1547 [2:33:34<18:55,  7.05s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(28, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  90%|█████████ | 1395/1547 [2:34:35<16:43,  6.61s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(7, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  97%|█████████▋| 1507/1547 [2:47:02<04:26,  6.67s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(15, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time:  10295.75 s\n",
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating train:  22%|██▏       | 17/78 [01:57<06:55,  6.81s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(46, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating train:  29%|██▉       | 23/78 [02:40<06:24,  6.99s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(39, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making plots. Saved location: plots/epochs/epoch26/train\n",
      "Saving plot at plots/epochs/epoch26/train/EtEi.png\n",
      "Saving plot at plots/epochs/epoch26/train/grad.png\n",
      "Saving plot at plots/epochs/epoch26/train/PerAtomEn.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating valid:  88%|████████▊ | 85/97 [09:39<01:29,  7.49s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(44, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making plots. Saved location: plots/epochs/epoch26/valid\n",
      "Saving plot at plots/epochs/epoch26/valid/EtEi.png\n",
      "Saving plot at plots/epochs/epoch26/valid/grad.png\n",
      "Saving plot at plots/epochs/epoch26/valid/PerAtomEn.png\n",
      "                       train         valid\n",
      "------------------------------------------\n",
      "TperAtom MAE:       0.018766      0.018376\n",
      "Force-RMSE  :    *   0.30037   *    0.3003\n",
      "Force-MAE   :    *   0.20329   *   0.20124\n",
      "Force-RSQ   :        0.97748       0.97761\n",
      "MolEn-RMSE  :        0.29212       0.27798\n",
      "MolEn-MAE   :        0.22721       0.22068\n",
      "MolEn-RSQ   :         0.9995       0.99956\n",
      "L2Reg       :         759.26        759.26\n",
      "Loss-Err    :        0.94816       0.92942\n",
      "Loss-Reg    :     0.00075926    0.00075926\n",
      "Loss        :        0.94892       0.93018\n",
      "Best Loss-Err so far:  0.90595\n",
      "Epochs since last best: 3\n",
      "Current max epochs: 43\n",
      "Total epoch time:  11502.34 s\n",
      "__________________________________________________\n",
      "Epoch 27:\n",
      "Learning rate:    0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:   0%|          | 1/1547 [00:06<2:42:48,  6.32s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(28, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  13%|█▎        | 205/1547 [22:44<2:28:27,  6.64s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(27, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  14%|█▎        | 212/1547 [23:31<2:27:25,  6.63s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(23, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  14%|█▍        | 223/1547 [24:46<2:25:36,  6.60s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(1, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  16%|█▌        | 251/1547 [27:55<2:24:45,  6.70s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(15, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  33%|███▎      | 515/1547 [57:20<1:58:11,  6.87s/batch]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Training Batches:  80%|███████▉  | 1234/1547 [2:18:16<35:36,  6.82s/batch]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(0, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  86%|████████▌ | 1330/1547 [2:29:14<24:19,  6.73s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(19, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  98%|█████████▊| 1513/1547 [2:49:56<03:51,  6.82s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(28, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time:  10423.62 s\n",
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating train:  62%|██████▏   | 48/78 [05:34<03:26,  6.88s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(9, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating train:  64%|██████▍   | 50/78 [05:49<03:20,  7.17s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(45, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating train:  95%|█████████▍| 74/78 [08:37<00:27,  6.89s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(17, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making plots. Saved location: plots/epochs/epoch28/train\n",
      "Saving plot at plots/epochs/epoch28/train/EtEi.png\n",
      "Saving plot at plots/epochs/epoch28/train/grad.png\n",
      "Saving plot at plots/epochs/epoch28/train/PerAtomEn.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating valid:  88%|████████▊ | 85/97 [09:41<01:28,  7.41s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(44, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making plots. Saved location: plots/epochs/epoch28/valid\n",
      "Saving plot at plots/epochs/epoch28/valid/EtEi.png\n",
      "Saving plot at plots/epochs/epoch28/valid/grad.png\n",
      "Saving plot at plots/epochs/epoch28/valid/PerAtomEn.png\n",
      "                       train         valid\n",
      "------------------------------------------\n",
      "TperAtom MAE:    *  0.013818   *  0.013376\n",
      "Force-RMSE  :    *   0.29873   *   0.29597\n",
      "Force-MAE   :    *   0.19985   *   0.19833\n",
      "Force-RSQ   :        0.97802       0.97825\n",
      "MolEn-RMSE  :    *   0.22481   *   0.21419\n",
      "MolEn-MAE   :    *   0.16831   *   0.16262\n",
      "MolEn-RSQ   :        0.99973       0.99974\n",
      "L2Reg       :          787.7         787.7\n",
      "Loss-Err    :    *   0.84116   *    0.8238\n",
      "Loss-Reg    :      0.0007877     0.0007877\n",
      "Loss        :    *   0.84195   *   0.82459\n",
      "Best Loss-Err so far:   0.8238\n",
      "Epochs since last best: 0\n",
      "Current max epochs: 48\n",
      "Total epoch time:  11637.95 s\n",
      "from callback update_scf_eps\n",
      "SCF eps is updated:  3.031775006720001e-05 ==> 2.789233006182401e-05\n",
      "**** NEW BEST MODEL - Saving! ****\n",
      "__________________________________________________\n",
      "Epoch 29:\n",
      "Learning rate:    0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  12%|█▏        | 187/1547 [21:18<2:33:17,  6.76s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(23, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  24%|██▎       | 365/1547 [41:26<2:11:51,  6.69s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(23, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  35%|███▌      | 549/1547 [1:02:13<1:50:08,  6.62s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(0, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  38%|███▊      | 595/1547 [1:07:26<1:49:32,  6.90s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(24, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  42%|████▏     | 656/1547 [1:14:20<1:39:07,  6.67s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(7, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  49%|████▉     | 758/1547 [1:25:43<1:26:47,  6.60s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(23, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  56%|█████▌    | 861/1547 [1:37:36<1:18:23,  6.86s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(30, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  78%|███████▊  | 1204/1547 [2:16:19<39:32,  6.92s/batch]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(10, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  91%|█████████ | 1408/1547 [2:39:33<15:59,  6.90s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(10, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  99%|█████████▉| 1532/1547 [2:53:39<01:41,  6.75s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(18, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time:  10518.13 s\n",
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making plots. Saved location: plots/epochs/epoch29/train\n",
      "Saving plot at plots/epochs/epoch29/train/EtEi.png\n",
      "Saving plot at plots/epochs/epoch29/train/grad.png\n",
      "Saving plot at plots/epochs/epoch29/train/PerAtomEn.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating valid:  88%|████████▊ | 85/97 [09:47<01:29,  7.48s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(44, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making plots. Saved location: plots/epochs/epoch29/valid\n",
      "Saving plot at plots/epochs/epoch29/valid/EtEi.png\n",
      "Saving plot at plots/epochs/epoch29/valid/grad.png\n",
      "Saving plot at plots/epochs/epoch29/valid/PerAtomEn.png\n",
      "                       train         valid\n",
      "------------------------------------------\n",
      "TperAtom MAE:       0.043032      0.042354\n",
      "Force-RMSE  :        0.30808        0.3088\n",
      "Force-MAE   :        0.20746       0.20784\n",
      "Force-RSQ   :        0.97621       0.97633\n",
      "MolEn-RMSE  :        0.61497       0.60796\n",
      "MolEn-MAE   :        0.51865       0.50959\n",
      "MolEn-RSQ   :        0.99775       0.99788\n",
      "L2Reg       :          803.6         803.6\n",
      "Loss-Err    :         1.4468         1.435\n",
      "Loss-Reg    :      0.0008036     0.0008036\n",
      "Loss        :         1.4476        1.4358\n",
      "Best Loss-Err so far:   0.8238\n",
      "Epochs since last best: 1\n",
      "Current max epochs: 48\n",
      "Total epoch time:  11743.18 s\n",
      "__________________________________________________\n",
      "Epoch 30:\n",
      "Learning rate:    0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:   1%|▏         | 23/1547 [02:37<2:53:35,  6.83s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(26, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  13%|█▎        | 200/1547 [22:34<2:33:00,  6.82s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(30, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  28%|██▊       | 440/1547 [49:52<2:07:40,  6.92s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(22, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  37%|███▋      | 579/1547 [1:05:42<1:49:37,  6.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(27, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  44%|████▍     | 677/1547 [1:16:55<1:37:58,  6.76s/batch]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Training Batches:  37%|███▋      | 565/1547 [1:04:04<1:51:35,  6.82s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(1, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  41%|████      | 629/1547 [1:11:25<1:43:36,  6.77s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(13, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  57%|█████▋    | 875/1547 [1:39:13<1:16:31,  6.83s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(31, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  59%|█████▊    | 906/1547 [1:42:46<1:10:44,  6.62s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(10, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  66%|██████▌   | 1022/1547 [1:56:01<1:00:40,  6.93s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(17, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  68%|██████▊   | 1053/1547 [1:59:33<56:56,  6.92s/batch]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(3, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  78%|███████▊  | 1206/1547 [2:16:51<38:27,  6.77s/batch]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(21, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  79%|███████▉  | 1229/1547 [2:19:29<36:26,  6.88s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(18, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  88%|████████▊ | 1355/1547 [2:33:47<21:45,  6.80s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(5, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time:  10521.71 s\n",
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating train:  29%|██▉       | 23/78 [02:40<06:20,  6.92s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(50, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating train:  62%|██████▏   | 48/78 [05:34<03:27,  6.90s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(62, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making plots. Saved location: plots/epochs/epoch33/train\n",
      "Saving plot at plots/epochs/epoch33/train/EtEi.png\n",
      "Saving plot at plots/epochs/epoch33/train/grad.png\n",
      "Saving plot at plots/epochs/epoch33/train/PerAtomEn.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making plots. Saved location: plots/epochs/epoch33/valid\n",
      "Saving plot at plots/epochs/epoch33/valid/EtEi.png\n",
      "Saving plot at plots/epochs/epoch33/valid/grad.png\n",
      "Saving plot at plots/epochs/epoch33/valid/PerAtomEn.png\n",
      "                       train         valid\n",
      "------------------------------------------\n",
      "TperAtom MAE:       0.017114      0.017069\n",
      "Force-RMSE  :    *   0.28688   *   0.28058\n",
      "Force-MAE   :    *   0.18781   *   0.18717\n",
      "Force-RSQ   :        0.97986       0.98046\n",
      "MolEn-RMSE  :        0.26974       0.26419\n",
      "MolEn-MAE   :         0.2045       0.20325\n",
      "MolEn-RSQ   :        0.99959        0.9996\n",
      "L2Reg       :         860.05        860.05\n",
      "Loss-Err    :        0.88202       0.86955\n",
      "Loss-Reg    :     0.00086005    0.00086005\n",
      "Loss        :        0.88288       0.87041\n",
      "Best Loss-Err so far:   0.8238\n",
      "Epochs since last best: 5\n",
      "Current max epochs: 48\n",
      "Total epoch time:  11738.48 s\n",
      "__________________________________________________\n",
      "Epoch 34:\n",
      "Learning rate:    0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:   6%|▌         | 90/1547 [10:09<2:41:52,  6.67s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(8, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:   9%|▉         | 142/1547 [16:03<2:35:43,  6.65s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(16, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  14%|█▍        | 224/1547 [25:20<2:27:47,  6.70s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(17, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  33%|███▎      | 510/1547 [57:20<1:55:17,  6.67s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(27, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  41%|████▏     | 641/1547 [1:12:18<1:42:06,  6.76s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(4, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  42%|████▏     | 657/1547 [1:14:09<1:42:32,  6.91s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(6, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  48%|████▊     | 749/1547 [1:24:36<1:28:57,  6.69s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(25, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  51%|█████     | 789/1547 [1:29:10<1:26:03,  6.81s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(13, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  63%|██████▎   | 982/1547 [1:51:03<1:04:06,  6.81s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(8, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  85%|████████▌ | 1322/1547 [2:29:35<25:47,  6.88s/batch]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(10, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time:  10489.81 s\n",
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating train:  83%|████████▎ | 65/78 [07:35<01:31,  7.07s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(0, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making plots. Saved location: plots/epochs/epoch34/train\n",
      "Saving plot at plots/epochs/epoch34/train/EtEi.png\n",
      "Saving plot at plots/epochs/epoch34/train/grad.png\n",
      "Saving plot at plots/epochs/epoch34/train/PerAtomEn.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating valid:  88%|████████▊ | 85/97 [09:44<01:29,  7.46s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(44, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making plots. Saved location: plots/epochs/epoch34/valid\n",
      "Saving plot at plots/epochs/epoch34/valid/EtEi.png\n",
      "Saving plot at plots/epochs/epoch34/valid/grad.png\n",
      "Saving plot at plots/epochs/epoch34/valid/PerAtomEn.png\n",
      "                       train         valid\n",
      "------------------------------------------\n",
      "TperAtom MAE:       0.046909       0.04696\n",
      "Force-RMSE  :    *   0.27994   *   0.27845\n",
      "Force-MAE   :        0.18952       0.18797\n",
      "Force-RSQ   :         0.9807       0.98075\n",
      "MolEn-RMSE  :        0.63145       0.63062\n",
      "MolEn-MAE   :        0.57345       0.57077\n",
      "MolEn-RSQ   :        0.99774       0.99771\n",
      "L2Reg       :         872.05        872.05\n",
      "Loss-Err    :         1.4594        1.4536\n",
      "Loss-Reg    :     0.00087205    0.00087205\n",
      "Loss        :         1.4603        1.4545\n",
      "Best Loss-Err so far:   0.8238\n",
      "Raising batch size to 64\n",
      "Epochs since last best: 6\n",
      "Current max epochs: 48\n",
      "Total epoch time:  11710.32 s\n",
      "__________________________________________________\n",
      "Epoch 35:\n",
      "Learning rate:    0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  19%|█▉        | 148/774 [26:49<1:56:36, 11.18s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(31, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  26%|██▋       | 204/774 [37:01<1:42:47, 10.82s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(12, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  27%|██▋       | 207/774 [37:36<1:47:04, 11.33s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(10, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  37%|███▋      | 285/774 [51:49<1:27:58, 10.79s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(3, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  44%|████▍     | 339/774 [1:01:36<1:18:32, 10.83s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(29, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  52%|█████▏    | 399/774 [1:12:34<1:09:16, 11.08s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(23, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  64%|██████▍   | 498/774 [1:30:38<49:49, 10.83s/batch]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(42, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  93%|█████████▎| 716/774 [2:10:16<11:08, 11.53s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(14, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  97%|█████████▋| 749/774 [2:16:17<04:28, 10.75s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(12, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time:  8439.8 s\n",
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating train:  49%|████▊     | 38/78 [04:28<04:41,  7.04s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(14, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating train:  71%|███████   | 55/78 [06:28<02:42,  7.06s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(31, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making plots. Saved location: plots/epochs/epoch35/train\n",
      "Saving plot at plots/epochs/epoch35/train/EtEi.png\n",
      "Saving plot at plots/epochs/epoch35/train/grad.png\n",
      "Saving plot at plots/epochs/epoch35/train/PerAtomEn.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating valid:  88%|████████▊ | 85/97 [09:48<01:29,  7.48s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(44, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making plots. Saved location: plots/epochs/epoch35/valid\n",
      "Saving plot at plots/epochs/epoch35/valid/EtEi.png\n",
      "Saving plot at plots/epochs/epoch35/valid/grad.png\n",
      "Saving plot at plots/epochs/epoch35/valid/PerAtomEn.png\n",
      "                       train         valid\n",
      "------------------------------------------\n",
      "TperAtom MAE:       0.032341      0.031812\n",
      "Force-RMSE  :        0.28259       0.27961\n",
      "Force-MAE   :        0.19033       0.18891\n",
      "Force-RSQ   :        0.98004       0.98059\n",
      "MolEn-RMSE  :        0.48115       0.47516\n",
      "MolEn-MAE   :        0.40173       0.39402\n",
      "MolEn-RSQ   :        0.99869        0.9987\n",
      "L2Reg       :         879.28        879.28\n",
      "Loss-Err    :         1.2079        1.1924\n",
      "Loss-Reg    :     0.00087928    0.00087928\n",
      "Loss        :         1.2088        1.1933\n",
      "Best Loss-Err so far:   0.8238\n",
      "Epochs since last best: 7\n",
      "Current max epochs: 48\n",
      "Total epoch time:  9667.41 s\n",
      "__________________________________________________\n",
      "Epoch 36:\n",
      "Learning rate:    0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:   4%|▍         | 30/774 [05:25<2:13:02, 10.73s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(22, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:   7%|▋         | 56/774 [10:09<2:08:19, 10.72s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(25, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  19%|█▉        | 149/774 [26:59<1:54:09, 10.96s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(57, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  34%|███▎      | 261/774 [47:15<1:32:12, 10.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(27, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  45%|████▌     | 351/774 [1:03:32<1:16:48, 10.90s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(43, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  53%|█████▎    | 410/774 [1:14:16<1:07:07, 11.06s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(5, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  68%|██████▊   | 524/774 [1:34:52<45:23, 10.89s/batch]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(7, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  78%|███████▊  | 604/774 [1:49:22<30:32, 10.78s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(9, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  95%|█████████▍| 733/774 [2:12:41<07:37, 11.16s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(44, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time:  8393.6 s\n",
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating train:   4%|▍         | 3/78 [00:21<08:45,  7.01s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(41, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating train:  27%|██▋       | 21/78 [02:29<06:40,  7.03s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(14, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making plots. Saved location: plots/epochs/epoch36/train\n",
      "Saving plot at plots/epochs/epoch36/train/EtEi.png\n",
      "Saving plot at plots/epochs/epoch36/train/grad.png\n",
      "Saving plot at plots/epochs/epoch36/train/PerAtomEn.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating valid:  88%|████████▊ | 85/97 [09:50<01:30,  7.52s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(44, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making plots. Saved location: plots/epochs/epoch36/valid\n",
      "Saving plot at plots/epochs/epoch36/valid/EtEi.png\n",
      "Saving plot at plots/epochs/epoch36/valid/grad.png\n",
      "Saving plot at plots/epochs/epoch36/valid/PerAtomEn.png\n",
      "                       train         valid\n",
      "------------------------------------------\n",
      "TperAtom MAE:       0.024564       0.02486\n",
      "Force-RMSE  :    *   0.27695   *    0.2746\n",
      "Force-MAE   :    *    0.1859   *   0.18462\n",
      "Force-RSQ   :        0.98135       0.98128\n",
      "MolEn-RMSE  :        0.37403       0.37324\n",
      "MolEn-MAE   :        0.31193       0.31271\n",
      "MolEn-RSQ   :        0.99919        0.9992\n",
      "L2Reg       :         884.64        884.64\n",
      "Loss-Err    :         1.0385        1.0349\n",
      "Loss-Reg    :     0.00088464    0.00088464\n",
      "Loss        :         1.0394        1.0357\n",
      "Best Loss-Err so far:   0.8238\n",
      "Epochs since last best: 8\n",
      "Current max epochs: 48\n",
      "Total epoch time:  9629.77 s\n",
      "__________________________________________________\n",
      "Epoch 37:\n",
      "Learning rate:    0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:   1%|          | 8/774 [01:28<2:21:40, 11.10s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(13, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  15%|█▌        | 118/774 [21:27<1:57:34, 10.75s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(19, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  29%|██▊       | 222/774 [40:15<1:39:36, 10.83s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(53, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  38%|███▊      | 295/774 [53:28<1:27:15, 10.93s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(47, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  42%|████▏     | 322/774 [58:25<1:22:44, 10.98s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(32, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  54%|█████▎    | 415/774 [1:15:24<1:04:19, 10.75s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(53, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  64%|██████▍   | 496/774 [1:30:07<54:17, 11.72s/batch]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(26, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  67%|██████▋   | 520/774 [1:34:26<44:53, 10.61s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(10, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  82%|████████▏ | 631/774 [1:54:21<25:34, 10.73s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(29, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  95%|█████████▍| 733/774 [2:12:47<07:20, 10.75s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(33, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time:  8401.85 s\n",
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making plots. Saved location: plots/epochs/epoch37/train\n",
      "Saving plot at plots/epochs/epoch37/train/EtEi.png\n",
      "Saving plot at plots/epochs/epoch37/train/grad.png\n",
      "Saving plot at plots/epochs/epoch37/train/PerAtomEn.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making plots. Saved location: plots/epochs/epoch37/valid\n",
      "Saving plot at plots/epochs/epoch37/valid/EtEi.png\n",
      "Saving plot at plots/epochs/epoch37/valid/grad.png\n",
      "Saving plot at plots/epochs/epoch37/valid/PerAtomEn.png\n",
      "                       train         valid\n",
      "------------------------------------------\n",
      "TperAtom MAE:       0.079587      0.079955\n",
      "Force-RMSE  :        0.28881       0.28903\n",
      "Force-MAE   :        0.19589       0.19441\n",
      "Force-RSQ   :        0.97931       0.97927\n",
      "MolEn-RMSE  :         1.0416        1.0368\n",
      "MolEn-MAE   :         0.9918       0.98747\n",
      "MolEn-RSQ   :        0.99387       0.99382\n",
      "L2Reg       :         891.65        891.65\n",
      "Loss-Err    :         2.1388        2.1302\n",
      "Loss-Reg    :     0.00089165    0.00089165\n",
      "Loss        :         2.1397        2.1311\n",
      "Best Loss-Err so far:   0.8238\n",
      "Epochs since last best: 9\n",
      "Current max epochs: 48\n",
      "Total epoch time:  9627.79 s\n",
      "__________________________________________________\n",
      "Epoch 38:\n",
      "Learning rate:    0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  24%|██▍       | 188/774 [34:08<1:46:47, 10.93s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(49, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  31%|███       | 240/774 [43:36<1:35:51, 10.77s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(35, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  35%|███▍      | 268/774 [48:45<1:34:36, 11.22s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(25, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  44%|████▎     | 338/774 [1:01:29<1:18:32, 10.81s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(41, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  53%|█████▎    | 408/774 [1:14:09<1:05:22, 10.72s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(1, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  59%|█████▉    | 457/774 [1:23:04<57:26, 10.87s/batch]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(43, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  65%|██████▍   | 503/774 [1:31:21<48:01, 10.63s/batch]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(33, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  67%|██████▋   | 518/774 [1:34:05<45:58, 10.77s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(34, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  78%|███████▊  | 600/774 [1:49:01<31:24, 10.83s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(57, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  88%|████████▊ | 678/774 [2:03:23<17:13, 10.77s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(23, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time:  8434.28 s\n",
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making plots. Saved location: plots/epochs/epoch38/train\n",
      "Saving plot at plots/epochs/epoch38/train/EtEi.png\n",
      "Saving plot at plots/epochs/epoch38/train/grad.png\n",
      "Saving plot at plots/epochs/epoch38/train/PerAtomEn.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making plots. Saved location: plots/epochs/epoch38/valid\n",
      "Saving plot at plots/epochs/epoch38/valid/EtEi.png\n",
      "Saving plot at plots/epochs/epoch38/valid/grad.png\n",
      "Saving plot at plots/epochs/epoch38/valid/PerAtomEn.png\n",
      "                       train         valid\n",
      "------------------------------------------\n",
      "TperAtom MAE:       0.057585      0.057878\n",
      "Force-RMSE  :        0.28485       0.28738\n",
      "Force-MAE   :        0.19415       0.19443\n",
      "Force-RSQ   :        0.97964        0.9795\n",
      "MolEn-RMSE  :        0.75737       0.76093\n",
      "MolEn-MAE   :        0.70334       0.70506\n",
      "MolEn-RSQ   :        0.99668       0.99667\n",
      "L2Reg       :         899.73        899.73\n",
      "Loss-Err    :          1.679        1.6861\n",
      "Loss-Reg    :     0.00089973    0.00089973\n",
      "Loss        :         1.6799         1.687\n",
      "Best Loss-Err so far:   0.8238\n",
      "Epochs since last best: 10\n",
      "Current max epochs: 48\n",
      "Total epoch time:  9651.45 s\n",
      "__________________________________________________\n",
      "Epoch 39:\n",
      "Learning rate:    0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:   7%|▋         | 52/774 [09:18<2:09:15, 10.74s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(0, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:   8%|▊         | 59/774 [10:36<2:09:21, 10.85s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(20, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  18%|█▊        | 137/774 [24:45<1:57:40, 11.08s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(36, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  31%|███▏      | 243/774 [43:55<1:35:10, 10.75s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(48, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  32%|███▏      | 251/774 [45:26<1:35:15, 10.93s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(36, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  58%|█████▊    | 446/774 [1:20:45<1:02:14, 11.39s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(19, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  65%|██████▍   | 503/774 [1:31:06<49:30, 10.96s/batch]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(10, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  95%|█████████▍| 732/774 [2:12:08<07:30, 10.72s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(18, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time:  8372.94 s\n",
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making plots. Saved location: plots/epochs/epoch39/train\n",
      "Saving plot at plots/epochs/epoch39/train/EtEi.png\n",
      "Saving plot at plots/epochs/epoch39/train/grad.png\n",
      "Saving plot at plots/epochs/epoch39/train/PerAtomEn.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making plots. Saved location: plots/epochs/epoch39/valid\n",
      "Saving plot at plots/epochs/epoch39/valid/EtEi.png\n",
      "Saving plot at plots/epochs/epoch39/valid/grad.png\n",
      "Saving plot at plots/epochs/epoch39/valid/PerAtomEn.png\n",
      "                       train         valid\n",
      "------------------------------------------\n",
      "TperAtom MAE:        0.02586       0.02648\n",
      "Force-RMSE  :        0.29139        0.2899\n",
      "Force-MAE   :        0.19483       0.19308\n",
      "Force-RSQ   :          0.979       0.97914\n",
      "MolEn-RMSE  :        0.37271       0.37738\n",
      "MolEn-MAE   :        0.30998       0.31443\n",
      "MolEn-RSQ   :        0.99917       0.99918\n",
      "L2Reg       :         906.88        906.88\n",
      "Loss-Err    :         1.0595        1.0635\n",
      "Loss-Reg    :     0.00090688    0.00090688\n",
      "Loss        :         1.0604        1.0645\n",
      "Best Loss-Err so far:   0.8238\n",
      "Epochs since last best: 11\n",
      "Current max epochs: 48\n",
      "Total epoch time:  9595.65 s\n",
      "__________________________________________________\n",
      "Epoch 40:\n",
      "Learning rate:    0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:   5%|▍         | 38/774 [06:52<2:10:47, 10.66s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(46, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  11%|█         | 87/774 [15:41<2:05:21, 10.95s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(2, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  13%|█▎        | 102/774 [18:24<1:59:20, 10.66s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(14, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  36%|███▌      | 278/774 [50:22<1:29:03, 10.77s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(56, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  37%|███▋      | 286/774 [51:50<1:26:29, 10.63s/batch]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Training Batches:  96%|█████████▌| 370/387 [1:59:21<05:27, 19.26s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(32, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time:  7480.41 s\n",
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making plots. Saved location: plots/epochs/epoch41/train\n",
      "Saving plot at plots/epochs/epoch41/train/EtEi.png\n",
      "Saving plot at plots/epochs/epoch41/train/grad.png\n",
      "Saving plot at plots/epochs/epoch41/train/PerAtomEn.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making plots. Saved location: plots/epochs/epoch41/valid\n",
      "Saving plot at plots/epochs/epoch41/valid/EtEi.png\n",
      "Saving plot at plots/epochs/epoch41/valid/grad.png\n",
      "Saving plot at plots/epochs/epoch41/valid/PerAtomEn.png\n",
      "                       train         valid\n",
      "------------------------------------------\n",
      "TperAtom MAE:       0.037154      0.037456\n",
      "Force-RMSE  :    *   0.27388       0.27588\n",
      "Force-MAE   :    *   0.18397   *   0.18375\n",
      "Force-RSQ   :        0.98112       0.98111\n",
      "MolEn-RMSE  :        0.50599       0.50993\n",
      "MolEn-MAE   :        0.44907       0.44952\n",
      "MolEn-RSQ   :        0.99848       0.99851\n",
      "L2Reg       :         917.43        917.43\n",
      "Loss-Err    :         1.2533        1.2586\n",
      "Loss-Reg    :     0.00091743    0.00091743\n",
      "Loss        :         1.2542        1.2595\n",
      "Best Loss-Err so far:   0.8238\n",
      "Epochs since last best: 13\n",
      "Current max epochs: 48\n",
      "Total epoch time:  8699.38 s\n",
      "__________________________________________________\n",
      "Epoch 42:\n",
      "Learning rate:    0.0003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:   2%|▏         | 6/387 [01:53<2:00:22, 18.96s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(53, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:   3%|▎         | 11/387 [03:32<2:02:07, 19.49s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(126, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  10%|▉         | 38/387 [12:12<1:52:29, 19.34s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(104, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  33%|███▎      | 128/387 [41:15<1:21:25, 18.86s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "did not converge 1\n",
      "not converged:  tensor(48, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Batches:  38%|███▊      | 147/387 [47:24<1:17:34, 19.39s/batch]"
     ]
    }
   ],
   "source": [
    "\n",
    "########\n",
    "#current_dir = '.../PYSEQM_dev/examples/hipnn_training/'\n",
    "current_dir = '/home/maxim/Projects/git2/PYSEQM_dev/examples/hipnn_training/'\n",
    "os.chdir(current_dir)\n",
    "\n",
    "def main():\n",
    "\n",
    "    ### directory csv with semiempirical parameters ###\n",
    "    parameter_file_dir = \"/home/maxim/Projects/git2/PYSEQM_dev//seqm/params\"\n",
    "    \n",
    "    ### directory with training set ###\n",
    "    dataset_path = \"/home/maxim/Projects/git2/PYSEQM_dev//examples/hipnn_training/training_set/\" \n",
    "    \n",
    "    ### Prefix for arrays in folder ###\n",
    "    dataset_name = ''\n",
    "\n",
    "    ### folder with models and plots ###\n",
    "    netname = 'TEST1'\n",
    "    dirname = netname\n",
    "    if not os.path.exists(dirname):\n",
    "        os.mkdir(dirname)\n",
    "    else:\n",
    "        pass\n",
    "        #raise ValueError(\"Directory {} already exists!\".format(dirname))\n",
    "    os.chdir(dirname)\n",
    "\n",
    "    TAG = 1 #False (0): first run, True(n): continue\n",
    "\n",
    "    dtype=torch.float64\n",
    "    torch.set_default_dtype(dtype)\n",
    "    device = torch.device('cuda')\n",
    "    DEVICE = 'cuda'\n",
    "\n",
    "\n",
    "    ### list of parameters to be learned ###\n",
    "    #\"\"\"\n",
    "    learned = ['U_ss', 'U_pp',\n",
    "               'zeta_s', 'zeta_p',\n",
    "               #'beta_s', \n",
    "               'beta_p',\n",
    "               #'g_ss',\n",
    "               'g_sp', 'g_pp', 'g_p2', 'h_sp',\n",
    "               #'alpha',\n",
    "           # 'Gaussian1_K', 'Gaussian2_K', #'Gaussian3_K','Gaussian4_K',\n",
    "           # 'Gaussian1_L', 'Gaussian2_L', #'Gaussian3_L','Gaussian4_L',\n",
    "           # 'Gaussian1_M', 'Gaussian2_M', #'Gaussian3_M','Gaussian4_M',\n",
    "          ]\n",
    "    #\"\"\"\n",
    "\n",
    "    \n",
    "    ### SEQM parameters ###\n",
    "    seqm_parameters = {\n",
    "                \"method\": \"PM6_SP\",  # AM1, MNDO, PM3#\n",
    "                \"scf_eps\": 5.0e-5,  # unit eV, change of electric energy, as nuclear energy doesnt' change during SCF\n",
    "                   'scf_converger' : [0,0.5], # converger used for scf loop\n",
    "                                           # [0, 0.1], [0, alpha] constant mixing, P = alpha*P + (1.0-alpha)*Pnew\n",
    "                                           # [1], adaptive mixing\n",
    "                                           # [1, K, L, M] # advanced adaptive mixing.\n",
    "                                           # First, it does linear mixing for M steps. Mixing coeff is K the first 5 SCF steps.\n",
    "                                           # Then it incrementally goes to L and becomes L at M-5 SCF step. From M-5 to M it's equal to L. After M'th SCF step, adaptive mixing begins.\n",
    "                                           # \n",
    "                                           # [2], adaptive mixing, then pulay\n",
    "                \"sp2\": [False, 1.0e-5],  # whether to use sp2 algorithm in scf loop,[True, eps] or [False], eps for SP2 conve criteria\n",
    "                \"elements\": [0, 1, 6, 7, 8],\n",
    "                \"learned\": learned,  # parameterlist[method], #['U_ss'], # learned parameters name list, e.g ['U_ss']\n",
    "                \"parameter_file_dir\": parameter_file_dir + \"/\",  # file directory for other required parameters\n",
    "                \"pair_outer_cutoff\": 1.0e10,  # consistent with the unit on coordinates\n",
    "                \"scf_backward\": 2, # 0: Hellmann–Feynman theorem, 1: recursive formula, 2: backpropagate through SCF (needed for training)\n",
    "                'UHF' : False, # use unrestricted HF\n",
    "                }\n",
    "\n",
    "    # Log the output of python to `training_log.txt`\n",
    "    with hippynn.tools.log_terminal(\"training_log_tag_%d.txt\" % TAG,'wt'):# and torch.autograd.set_detect_anomaly(True):\n",
    "\n",
    "        ### Hyperparameters for the network ###\n",
    "        network_params = {\n",
    "            \"possible_species\": [0,1,6,7,8],   # Z values of the elements\n",
    "            'n_features': 50,                     # Number of neurons at each layer\n",
    "            \"n_sensitivities\": 18,                # Number of sensitivity functions in an interaction layer\n",
    "            \"dist_soft_min\": 0.6,  # qm7 1.7  qm9 .85  AL100 .85\n",
    "            \"dist_soft_max\": 4.0,  # qm7 10.  qm9 5.   AL100 5.\n",
    "            \"dist_hard_max\": 5.0,  # qm7 15.  qm9 7.5  AL100 7.5\n",
    "            \"n_interaction_layers\": 2,            # Number of interaction blocks\n",
    "            \"n_atom_layers\": 3,                   # Number of atom layers in an interaction block\n",
    "        }\n",
    "\n",
    "\n",
    "        ### Define a model ###\n",
    "\n",
    "        species = inputs.SpeciesNode(db_name=\"Z\")\n",
    "\n",
    "        positions = inputs.PositionsNode(db_name=\"R\")\n",
    "\n",
    "        network = networks.Hipnn(\"HIPNN_seqm\", (species, positions), module_kwargs = network_params)\n",
    "\n",
    "        n_target_peratom = len(seqm_parameters[\"learned\"])\n",
    "\n",
    "        decay_factor = 1.0e-4\n",
    "        par_atom = HChargeNode(\"SEQM_Atom_Params\",network,module_kwargs=dict(n_target=n_target_peratom,first_is_interacting=True))\n",
    "        with torch.no_grad():\n",
    "            for layer in par_atom.torch_module.layers:\n",
    "                layer.weight.data *= decay_factor\n",
    "                layer.bias.data *= decay_factor\n",
    "\n",
    "        seqm_par = par_atom.atom_charges\n",
    "\n",
    "        lenergy = SEQM_AllNode(\"SEQM_Energy\",(par_atom, positions, species),seqm_parameters, decay_factor = 1.0e-4)\n",
    "\n",
    "        molecule_energy = lenergy.Etot_m_Eiso\n",
    "\n",
    "        gradient  = physics.GradientNode(\"gradients\", (molecule_energy, positions), sign=+1)\n",
    "\n",
    "        notconverged = lenergy.notconverged\n",
    "        scale = ScaleNode(\"Scale\", (notconverged,))\n",
    "\n",
    "        gradient.db_name='Gradient_ev'\n",
    "        molecule_energy.db_name=\"EtEi\"\n",
    "\n",
    "\n",
    "        mol_mask = SEQM_MolMaskNode(\"SEQM_MolMask\", notconverged)\n",
    "        atom_mask = AtomMaskNode(\"Atom_Mask\", species)\n",
    "        gradient_pred = SEQM_MaskOnMolAtomNode(\"SEQM_MaskMolAtom_Pred\", (gradient, mol_mask, atom_mask)).pred\n",
    "        gradient_true = SEQM_MaskOnMolAtomNode(\"SEQM_MaskMolAtom_True\", (gradient.true, mol_mask.pred, atom_mask.pred))\n",
    "\n",
    "        molecule_energy_pred = SEQM_MaskOnMolNode(\"SEQM_MaskMol_Pred\", (molecule_energy, mol_mask)).pred\n",
    "        molecule_energy_true = SEQM_MaskOnMolNode(\"SEQM_MaskMol_True\", (molecule_energy.true, mol_mask.pred))\n",
    "\n",
    "\n",
    "        ### define loss quantities ###\n",
    "\n",
    "        rmse_gradient = loss.MSELoss(gradient_pred, gradient_true) ** (1./2.)\n",
    "        rmse_mol_energy = loss.MSELoss(molecule_energy_pred, molecule_energy_true) ** (1. / 2.)\n",
    "\n",
    "\n",
    "        mae_gradient = loss.MAELoss(gradient_pred, gradient_true)\n",
    "        mae_mol_energy = loss.MAELoss(molecule_energy_pred, molecule_energy_true)\n",
    "\n",
    "        rsq_gradient = loss.Rsq(gradient_pred, gradient_true)\n",
    "        rsq_mol_energy = loss.Rsq(molecule_energy_pred, molecule_energy_true)\n",
    "\n",
    "        ### SLIGHTLY MORE ADVANCED USAGE\n",
    "\n",
    "        pred_per_atom1 = physics.PerAtom(\"PeratomPredicted\",(molecule_energy,species))\n",
    "        true_per_atom1 = physics.PerAtom(\"PeratomTrue\",(molecule_energy.true,species.true))\n",
    "        pred_per_atom = SEQM_MaskOnMolNode(\"SEQM_PerAtom_Pred\", (pred_per_atom1, mol_mask)).pred\n",
    "        true_per_atom = SEQM_MaskOnMolNode(\"SEQM_PerAtom_True\", (true_per_atom1.pred, mol_mask.pred))\n",
    "        mae_per_atom = loss.MAELoss(pred_per_atom,true_per_atom)\n",
    "        rmse_per_atom = loss.MSELoss(pred_per_atom,true_per_atom) ** (1. / 2.)\n",
    "\n",
    "        rmse_par = loss.MeanSq(seqm_par.pred)\n",
    "\n",
    "        ### END SLIGHTLY MORE ADVANCED USAGE\n",
    "\n",
    "        ratio = ValueNode(0.8)\n",
    "        ratio.name =\"EnCoeff\"\n",
    "        \n",
    "        \n",
    "        loss_error = rmse_gradient + mae_gradient + ratio*(rmse_mol_energy + mae_mol_energy) + 8.0*rmse_par #+ 0.2*(mae_mol_energy) #+ 0.5*rmse_par\n",
    "\n",
    "\n",
    "        #rbar = loss.Mean.of_node(hierarchicality)\n",
    "        l2_reg = loss.l2reg(network)\n",
    "        loss_regularization = 1.0e-6 * loss.Mean(l2_reg) #+ rbar    # L2 regularization and hierarchicality regularization\n",
    "\n",
    "        train_loss = loss_error*scale.pred + loss_regularization\n",
    "\n",
    "        # Validation losses are what we check on the data between epochs -- we can only train to\n",
    "        # a single loss, but we can check other metrics too to better understand how the model is training.\n",
    "        # There will also be plots of these things over time when training completes.\n",
    "        validation_losses = {\n",
    "            \"TperAtom RMSE\": rmse_per_atom,\n",
    "            \"TperAtom MAE\" : mae_per_atom,\n",
    "            \"Force-RMSE\"   : rmse_gradient,\n",
    "            \"Force-MAE\"    : mae_gradient,\n",
    "            \"Force-RSQ\"    : rsq_gradient,\n",
    "            \"MolEn-RMSE\"   : rmse_mol_energy,\n",
    "            \"MolEn-MAE\"    : mae_mol_energy,\n",
    "            \"MolEn-RSQ\"    : rsq_mol_energy,\n",
    "            \"L2Reg\"        : l2_reg,\n",
    "            \"Loss-Err\"     : loss_error,\n",
    "            \"Loss-Reg\"     : loss_regularization,\n",
    "            \"Loss\"         : train_loss,\n",
    "        }\n",
    "        early_stopping_key = \"Loss-Err\"\n",
    "\n",
    "\n",
    "\n",
    "        plot_maker = plotting.PlotMaker(\n",
    "            # Simple plots which compare the network to the database\n",
    "\n",
    "            #plotting.Hist2D.compare(molecule_energy, saved=True),\n",
    "            plotting.Hist2D(molecule_energy_true, molecule_energy_pred,\n",
    "                            xlabel=\"True EtEi\",ylabel=\"Predicted EtEi\",\n",
    "                            saved=\"EtEi.png\"),\n",
    "            plotting.Hist2D(gradient_true, gradient_pred,\n",
    "                            xlabel=\"True Force\",ylabel=\"Predicted Force\",\n",
    "                            saved=\"grad.png\"),\n",
    "\n",
    "            #Slightly more advanced control of plotting!\n",
    "            plotting.Hist2D(true_per_atom,pred_per_atom,\n",
    "                            xlabel=\"True Energy/Atom\",ylabel=\"Predicted Energy/Atom\",\n",
    "                            saved=\"PerAtomEn.png\"),\n",
    "\n",
    "            #plotting.HierarchicalityPlot(hierarchicality.pred,\n",
    "            #                             molecule_energy.pred - molecule_energy.true,\n",
    "            #                             saved=\"HierPlot.pdf\"),\n",
    "            plot_every=1,   # How often to make plots -- here, epoch 0, 10, 20...\n",
    "        )\n",
    "\n",
    "        if TAG==0: #TRAINING FROM SCRATCH\n",
    "\n",
    "\n",
    "            training_modules, db_info = \\\n",
    "                assemble_for_training(train_loss,validation_losses,plot_maker=plot_maker)\n",
    "            training_modules[0].print_structure()\n",
    "\n",
    "    # ----------------- #\n",
    "    # Step 3: RUN MODEL #\n",
    "    # ----------------- #\n",
    "\n",
    "            database_params = {\n",
    "                'name': dataset_name,                            # Prefix for arrays in folder\n",
    "                'directory': dataset_path,\n",
    "                'quiet': False,                           # Quiet==True: suppress info about loading database\n",
    "                'seed': 1,                       # Random seed for data splitting\n",
    "                #'test_size': 0.1,                # Fraction of data used for testing\n",
    "                #'valid_size':0.1,\n",
    "                **db_info                 # Adds the inputs and targets names from the model as things to load\n",
    "            }\n",
    "\n",
    "\n",
    "            database = DirectoryDatabase(**database_params)\n",
    "            \n",
    "            ### a fraction of the data set to ignore (i.e., 0.9 means to ignore 90% of the data set and use 10% for train/test/validation) ###\n",
    "            database.make_random_split(\"ignore\",0.9)\n",
    "            del database.splits['ignore']\n",
    "            database.make_trainvalidtest_split(test_size=0.1,valid_size=0.1)\n",
    "\n",
    "            #from hippynn.pretraining import set_e0_values\n",
    "            #set_e0_values(henergy,database,energy_name=\"T_transpose\",trainable_after=False)\n",
    "\n",
    "            init_lr = 0.5e-4\n",
    "            optimizer = torch.optim.Adam(training_modules.model.parameters(),lr=init_lr)\n",
    "\n",
    "\n",
    "\n",
    "            scheduler =  RaiseBatchSizeOnPlateau(optimizer=optimizer,\n",
    "                                                max_batch_size=128,\n",
    "                                                patience=5,\n",
    "                                                factor=0.5)\n",
    "\n",
    "            controller = PatienceController(optimizer=optimizer,\n",
    "                                            scheduler=scheduler,\n",
    "                                            batch_size=32,\n",
    "                                            eval_batch_size=64,\n",
    "                                            max_epochs=200,\n",
    "                                            termination_patience=20,\n",
    "                                            fraction_train_eval=0.1,\n",
    "                                            stopping_key=early_stopping_key,\n",
    "                                            )\n",
    "\n",
    "            scheduler.set_controller(controller)\n",
    "\n",
    "            experiment_params = hippynn.experiment.SetupParams(\n",
    "                controller = controller,\n",
    "                device=DEVICE,\n",
    "            )\n",
    "            print(experiment_params)\n",
    "\n",
    "            # Parameters describing the training procedure.\n",
    "\n",
    "            training_modules, controller, metric_tracker  = setup_training(training_modules=training_modules,\n",
    "                                                            setup_params=experiment_params)\n",
    "            \n",
    "        if TAG>0: #CONTINUE INTERRUPTED TRAINING\n",
    "            from hippynn.experiment.serialization import load_checkpoint_from_cwd, load_checkpoint\n",
    "            from hippynn.experiment import train_model\n",
    "            \n",
    "            #load best model\n",
    "            #structure = load_checkpoint_from_cwd()\n",
    "            \n",
    "            #load last model\n",
    "            structure = load_checkpoint(\"experiment_structure.pt\", \"last_checkpoint.pt\")\n",
    "            \n",
    "            training_modules = structure[\"training_modules\"]\n",
    "            \n",
    "            database = structure[\"database\"]\n",
    "            \n",
    "            ### a fraction of the data set to ignore (i.e., 0.9 means to ignore 90% of the data set and use 10% for train/test/validation) ###\n",
    "            database.make_random_split(\"ignore\",0.9)\n",
    "            del database.splits['ignore']\n",
    "            database.make_trainvalidtest_split(test_size=0.1,valid_size=0.1)\n",
    "            \n",
    "\n",
    "            \n",
    "            #controller = structure[\"controller\"]\n",
    "            \n",
    "            init_lr = 3.0e-4\n",
    "            optimizer = torch.optim.Adam(training_modules.model.parameters(),lr=init_lr)\n",
    "            \n",
    "            scheduler =  RaiseBatchSizeOnPlateau(optimizer=optimizer,\n",
    "                                                max_batch_size=128,\n",
    "                                                patience=5,\n",
    "                                                factor=0.5)\n",
    "            \n",
    "            controller = PatienceController(optimizer=optimizer,\n",
    "                                            scheduler=scheduler,\n",
    "                                            batch_size=32,\n",
    "                                            eval_batch_size=64,\n",
    "                                            max_epochs=100,\n",
    "                                            termination_patience=20,\n",
    "                                            fraction_train_eval=0.1,\n",
    "                                            stopping_key=early_stopping_key,\n",
    "                                            )\n",
    "            \n",
    "            metric_tracker = structure[\"metric_tracker\"]\n",
    "    \n",
    "    from hippynn.experiment import train_model\n",
    "    \n",
    "    store_all_better=True\n",
    "    store_best=True\n",
    "    if isinstance(training_modules[0], torch.nn.DataParallel):\n",
    "        seqm_module = training_modules[0].module.node_from_name('SEQM_Energy').torch_module\n",
    "    else:\n",
    "        seqm_module = training_modules[0].node_from_name('SEQM_Energy').torch_module\n",
    "    callbacks = [update_scf_eps(seqm_module, 0.92),\n",
    "                    save_and_stop_after(training_modules, controller, metric_tracker, store_all_better, store_best, [10,0,0,0])]\n",
    "    \n",
    "    train_model(training_modules=training_modules,\n",
    "                database=database,\n",
    "                controller=controller,\n",
    "                metric_tracker=metric_tracker,\n",
    "                callbacks=callbacks,batch_callbacks=None,\n",
    "                store_all_better=store_all_better,\n",
    "                store_best=store_best)\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2ac951-6e17-463a-9da6-9d5802c16b6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a54c0b-4092-45ae-bea5-f5d95117c821",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c540b0c5-e53b-47f7-b6c5-3ce947f8acd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3537b980-136a-4407-b1ce-88e3174b135c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hipnn_1",
   "language": "python",
   "name": "hipnn_1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
